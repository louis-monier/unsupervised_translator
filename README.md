# Exploiting Word Embeddings for Machine Translation

Project for the [IASD Master program](https://www.lamsade.dauphine.fr/wp/iasd/en/) between Paris-Dauphine, École Normale Supérieure, and Mines ParisTech.

Check the Jupyter Notebook: **unsupervised_translator**

Link to the project [report](https://drive.google.com/file/d/1SZ6m3ec6IeluMPjYQW8e4e8vmjG7Bhwp/view?usp=sharing) (french).

Link to the project presentation [slides](https://drive.google.com/file/d/1xF2RJM8jzjJ58_-Sde9ZTzGZ5TvRe9Rh/view?usp=sharing).

References:
* Mikolov, T., Le, Q.V., & Sutskever, I. (2013). Exploiting Similarities among Languages for Machine Translation. [[PDF]](https://arxiv.org/pdf/1309.4168.pdf), [[arXiv]](https://arxiv.org/abs/1309.4168).
* Xing, C., Wang, D., Liu, C., & Lin, Y. (2015). Normalized Word Embedding and Orthogonal Transform for Bilingual Word Translation. [[PDF]](https://www.aclweb.org/anthology/N15-1104.pdf)
* Conneau, A., Lample, G., Ranzato, M., Denoyer, L., & Jégou, H. (2018). Word Translation Without Parallel Data. [[PDF]](https://arxiv.org/pdf/1710.04087.pdf), [[arXiv]](https://arxiv.org/abs/1710.04087).
